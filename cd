import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
DF=pd.read_json(path_or_buf ="transactions.txt", lines=True)
Object_describe=DF.describe(include='object')
Int_describe=DF.describe(include='int')
Float_describe=DF.describe(include='float')
Bool_describe=DF.describe(include='bool')
CountNa=DF.isna().sum()
UniqueDF=DF.nunique().sort_values()

DF['depvar']=DF['isFraud']*1
DF['depvar'].sum()/DF['depvar'].count()

DF['accountOpenDate_new'] = pd.to_datetime(DF['accountOpenDate'],format='%Y-%m-%d %H:%M:%S',errors='coerce')
DF['dateOfLastAddressChange_new'] = pd.to_datetime(DF['dateOfLastAddressChange'],format='%Y-%m-%d %H:%M:%S',errors='coerce')
DF['transactionDateTime_new'] = pd.to_datetime(DF['transactionDateTime'],format='%Y-%m-%d',errors='coerce')
DF['currentExpDate_new'] = pd.to_datetime(DF['currentExpDate'])

DF['transactionDateTime_year']=DF['transactionDateTime_new'].dt.year
DF['transactionDateTime_month']=DF['transactionDateTime_new'].dt.month
DF['transactionDateTime_day']=DF['transactionDateTime_new'].dt.day
DF['transactionDateTime_hour']=DF['transactionDateTime_new'].dt.hour
DF['transactionDateTime_minute']=DF['transactionDateTime_new'].dt.minute
DF['transactionDateTime_seconds']=DF['transactionDateTime_new'].dt.second
DF['transactionDateTime_dayofweek']=DF['transactionDateTime_new'].dt.weekday

DF['account_tenure']=DF['transactionDateTime_new']-DF['accountOpenDate_new']
DF['address_change_tenure']=DF['transactionDateTime_new']-DF['dateOfLastAddressChange_new']
DF['dateOfLastAddressChange_accountOpenDate']=DF['dateOfLastAddressChange_new']-DF['accountOpenDate_new']
DF['transaction_currentExpDate']=DF['currentExpDate_new']-DF['transactionDateTime_new']
DF['dateOfLastAddressChange_currentExpDate']=DF['currentExpDate_new']-DF['dateOfLastAddressChange_new']
DF['accountOpenDate_currentExpDate']=DF['currentExpDate_new']-DF['accountOpenDate_new']

DF['account_tenure']=DF['account_tenure'].dt.days
DF['address_change_tenure']=DF['address_change_tenure'].dt.days
DF['dateOfLastAddressChange_accountOpenDate']=DF['dateOfLastAddressChange_accountOpenDate'].dt.days
DF['transaction_currentExpDate']=DF['transaction_currentExpDate'].dt.days
DF['dateOfLastAddressChange_currentExpDate']=DF['dateOfLastAddressChange_currentExpDate'].dt.days
DF['accountOpenDate_currentExpDate']=DF['accountOpenDate_currentExpDate'].dt.days
for vars in DF.select_dtypes(include='number').columns:
    DF[vars+'_bin']=pd.qcut(DF[vars],20, labels=False, retbins=False, duplicates='drop')
DF['wgt']=1
DF['depvar_comp']=DF['wgt']-DF['depvar']


F_pivot=DF.pivot_table(index='creditLimit',values=['wgt','depvar','depvar_comp'],aggfunc=np.sum)
DF_pivot['BadRate'] = DF_pivot['depvar'] / DF_pivot['wgt']
DF_pivot['depvar_comp_share']=DF_pivot['depvar_comp']/DF_pivot['depvar_comp'].sum()
DF_pivot['depvar_share']=DF_pivot['depvar']/DF_pivot['depvar'].sum()
DF_pivot['KS']=DF_pivot['depvar']/DF_pivot['depvar'].sum()-DF_pivot['depvar_comp']/DF_pivot['depvar_comp'].sum()
DF_pivot['variable']='creditLimit'
DF_pivot['values']=DF_pivot.index
DF_pivot.reset_index(drop=True,inplace=True)
DF_pivot.sort_values(by='BadRate',ascending=False)
DF_pivot

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

plt.rcParams["figure.figsize"] = (20,3)

for vars in DF.columns:
    if vars not in ['isFraud_','notFraud']:
        if 1< DF[vars].nunique() < 32:
            print(vars)
            DF_pivot=DF.pivot_table(index=vars,values=['wgt','isFraud_','notFraud'],aggfunc=np.sum)
            DF_pivot['FraudRate'] = DF_pivot['isFraud_'] / DF_pivot['wgt']
            DF_pivot['notFraud_share']=DF_pivot['notFraud']/DF_pivot['notFraud'].sum()
            DF_pivot['Fraud_share']=DF_pivot['isFraud_']/DF_pivot['isFraud_'].sum()
            DF_pivot['KS']=DF_pivot['isFraud_']/DF_pivot['isFraud_'].sum()-DF_pivot['notFraud']/DF_pivot['notFraud'].sum()
            DF_pivot['variable']=vars
            DF_pivot['values']=DF_pivot.index
            DF_pivot.reset_index(drop=True,inplace=True)
            DF_pivot.sort_values(by='FraudRate',ascending=False)

            width = .35 # width of a bar

            DF_pivot[['notFraud_share','Fraud_share']].plot(kind='bar', width = width)
            DF_pivot['FraudRate'].plot(secondary_y=True)
            ax = plt.gca()
            plt.xlim([-width, len(DF_pivot['notFraud_share'])-width])
            ax.set_xticklabels((DF_pivot['values']))
            plt.title(vars)
            plt.ylabel("FraudRate")
            plt.show()
            
# import packages
import pandas as pd
import numpy as np
import pandas.core.algorithms as algos
from pandas import Series
import scipy.stats.stats as stats
import re
import traceback
import string

max_bin = 20
force_bin = 3

# define a binning function
def mono_bin(Y, X, n = max_bin):
    
    df1 = pd.DataFrame({"X": X, "Y": Y})
    justmiss = df1[['X','Y']][df1.X.isnull()]
    notmiss = df1[['X','Y']][df1.X.notnull()]
    r = 0
    while np.abs(r) < 1:
        try:
            d1 = pd.DataFrame({"X": notmiss.X, "Y": notmiss.Y, "Bucket": pd.qcut(notmiss.X, n)})
            d2 = d1.groupby('Bucket', as_index=True)
            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)
            n = n - 1 
        except Exception as e:
            n = n - 1

    if len(d2) == 1:
        n = force_bin         
        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))
        if len(np.unique(bins)) == 2:
            bins = np.insert(bins, 0, 1)
            bins[1] = bins[1]-(bins[1]/2)
        d1 = pd.DataFrame({"X": notmiss.X, "Y": notmiss.Y, "Bucket": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) 
        d2 = d1.groupby('Bucket', as_index=True)
    
    d3 = pd.DataFrame({},index=[])
    d3["MIN_VALUE"] = d2.min().X
    d3["MAX_VALUE"] = d2.max().X
    d3["COUNT"] = d2.count().Y
    d3["EVENT"] = d2.sum().Y
    d3["NONEVENT"] = d2.count().Y - d2.sum().Y
    d3=d3.reset_index(drop=True)
    
    if len(justmiss.index) > 0:
        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])
        d4["MAX_VALUE"] = np.nan
        d4["COUNT"] = justmiss.count().Y
        d4["EVENT"] = justmiss.sum().Y
        d4["NONEVENT"] = justmiss.count().Y - justmiss.sum().Y
        d3 = d3.append(d4,ignore_index=True)
    
    d3["EVENT_RATE"] = d3.EVENT/d3.COUNT
    d3["NON_EVENT_RATE"] = d3.NONEVENT/d3.COUNT
    d3["DIST_EVENT"] = d3.EVENT/d3.sum().EVENT
    d3["DIST_NON_EVENT"] = d3.NONEVENT/d3.sum().NONEVENT
    d3["WOE"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)
    d3["IV"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)
    d3["VAR_NAME"] = "VAR"
    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       
    d3 = d3.replace([np.inf, -np.inf], 0)
    d3.IV = d3.IV.sum()
    
    return(d3)

def char_bin(Y, X):
        
    df1 = pd.DataFrame({"X": X, "Y": Y})
    justmiss = df1[['X','Y']][df1.X.isnull()]
    notmiss = df1[['X','Y']][df1.X.notnull()]    
    df2 = notmiss.groupby('X',as_index=True)
    
    d3 = pd.DataFrame({},index=[])
    d3["COUNT"] = df2.count().Y
    d3["MIN_VALUE"] = df2.sum().Y.index
    d3["MAX_VALUE"] = d3["MIN_VALUE"]
    d3["EVENT"] = df2.sum().Y
    d3["NONEVENT"] = df2.count().Y - df2.sum().Y
    
    if len(justmiss.index) > 0:
        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])
        d4["MAX_VALUE"] = np.nan
        d4["COUNT"] = justmiss.count().Y
        d4["EVENT"] = justmiss.sum().Y
        d4["NONEVENT"] = justmiss.count().Y - justmiss.sum().Y
        d3 = d3.append(d4,ignore_index=True)
    
    d3["EVENT_RATE"] = d3.EVENT/d3.COUNT
    d3["NON_EVENT_RATE"] = d3.NONEVENT/d3.COUNT
    d3["DIST_EVENT"] = d3.EVENT/d3.sum().EVENT
    d3["DIST_NON_EVENT"] = d3.NONEVENT/d3.sum().NONEVENT
    d3["WOE"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)
    d3["IV"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)
    d3["VAR_NAME"] = "VAR"
    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      
    d3 = d3.replace([np.inf, -np.inf], 0)
    d3.IV = d3.IV.sum()
    d3 = d3.reset_index(drop=True)
    
    return(d3)

def data_vars(df1, target):
    
    stack = traceback.extract_stack()
    filename, lineno, function_name, code = stack[-2]
    vars_name = re.compile(r'\((.*?)\).*$').search(code).groups()[0]
    final = (re.findall(r"[\w']+", vars_name))[-1]
    
    x = df1.dtypes.index
    count = -1
    
    for i in x:
        if i.upper() not in (final.upper()) and not any(i in s for s in exclude_list) :
            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 60:
                conv = mono_bin(target, df1[i])
                conv["VAR_NAME"] = i
                count = count + 1
            else:
                conv = char_bin(target, df1[i])
                conv["VAR_NAME"] = i            
                count = count + 1
                
            if count == 0:
                iv_df = conv
            else:
                iv_df = iv_df.append(conv,ignore_index=True)giyhub
                
    
    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})
    iv = iv.reset_index()
    return(iv_df,iv)
ls=[]
exclude_list = ['isFraud']




DF1['newinvnum']=(df['fund']!=df['fund'].shift(+1))*1
DF1['cumsum'] = df['newinvnum'].cumsum()
DF1['newinvnum']= df.groupby(['cumsum'])['wgt'].cumsum()
    
myDataFrame=myDataFrame.sort_values(by=['fund','modify_trade_date'], axis=0,ascending=[1,1])
marchDataFrame=marchDataFrame.sort_values(by=['fund','modify_trade_date'], axis=0,ascending=[1,1])
test_feb=test_feb.sort_values(by=['fund','modify_trade_date'], axis=0,ascending=[1,1])
for df in [myDataFrame,marchDataFrame,test_feb]:    
    df['newinvnum1']=(df['fund']!=df['fund'].shift(+1))*1
    df['cumsum'] = df['newinvnum1'].cumsum()
    df['newinvnum1']= df.groupby(['cumsum'])['wgt'].cumsum()
myDataFrame=myDataFrame.sort_values(by=['fund','invnum'], axis=0,ascending=[1,1])
myDataFrame=myDataFrame.sort_values(by=['fund','invnum'], axis=0,ascending=[1,1])
test_feb=test_feb.sort_values(by=['fund','invnum'], axis=0,ascending=[1,1])
